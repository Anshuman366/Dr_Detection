{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:\\projects\\Dr_Detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareCallbacksConfig:\n",
    "    root_dir: Path\n",
    "    tensorboard_root_log_dir: Path\n",
    "    checkpoint_model_filepath: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  Dr_detection.constants import *\n",
    "from Dr_detection.utils import read_yaml, create_directories\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_prepare_callback_config(self) -> PrepareCallbacksConfig:\n",
    "        config = self.config.prepare_callbacks\n",
    "        model_ckpt_dir = os.path.dirname(config.checkpoint_model_filepath)\n",
    "        create_directories([\n",
    "            Path(model_ckpt_dir),\n",
    "            Path(config.tensorboard_root_log_dir)\n",
    "        ])\n",
    "\n",
    "        prepare_callback_config = PrepareCallbacksConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            tensorboard_root_log_dir=Path(config.tensorboard_root_log_dir),\n",
    "            checkpoint_model_filepath=Path(config.checkpoint_model_filepath)\n",
    "        )\n",
    "\n",
    "        return prepare_callback_config\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"train\")\n",
    "        create_directories([\n",
    "            Path(training.root_dir)  \n",
    "            ])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class PrepareCallback:\n",
    "    def __init__(self, config: PrepareCallbacksConfig):\n",
    "        self.config = config\n",
    "\n",
    "    @property\n",
    "    def _create_tb_callbacks(self):\n",
    "        timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "        tb_running_log_dir = os.path.join(\n",
    "            self.config.tensorboard_root_log_dir,\n",
    "            f\"tb_logs_at_{timestamp}\",\n",
    "        )\n",
    "        return tf.keras.callbacks.TensorBoard(log_dir=tb_running_log_dir)\n",
    "\n",
    "    @property\n",
    "    def _create_ckpt_callbacks(self):\n",
    "        return tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=str(self.config.checkpoint_model_filepath),\n",
    "            save_best_only=True\n",
    "        )\n",
    "\n",
    "    def get_tb_ckpt_callbacks(self):\n",
    "        return [\n",
    "            self._create_tb_callbacks,\n",
    "            self._create_ckpt_callbacks\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale = 1./255,\n",
    "            validation_split=0.20\n",
    "        )\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                horizontal_flip=True,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "        else:\n",
    "            train_datagenerator = valid_datagenerator\n",
    "\n",
    "        self.train_generator = train_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"training\",\n",
    "            shuffle=True,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "\n",
    "    def train(self, callback_list: list):\n",
    "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
    "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
    "\n",
    "        self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.params_epochs,\n",
    "            steps_per_epoch=self.steps_per_epoch,\n",
    "            validation_steps=self.validation_steps,\n",
    "            validation_data=self.valid_generator,\n",
    "            callbacks=callback_list\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-03 12:55:33,669: INFO: common]: yaml file: configs\\config.yaml loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-03 12:55:33,794: INFO: common]: yaml file: params.yaml loaded successfully\n",
      "[2024-03-03 12:55:33,873: INFO: common]: created directory at: artifacts\n",
      "[2024-03-03 12:55:33,882: INFO: common]: created directory at: artifacts\\prepare_callbacks\\checkpoint_dir\n",
      "[2024-03-03 12:55:33,885: INFO: common]: created directory at: artifacts\\prepare_callbacks\\tensorboard_log_dir\n",
      "[2024-03-03 12:55:34,305: INFO: common]: created directory at: artifacts\\training\n",
      "Found 550 images belonging to 5 classes.\n",
      "Found 2200 images belonging to 5 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_callbacks_config = config.get_prepare_callback_config()\n",
    "    prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n",
    "    callback_list = prepare_callbacks.get_tb_ckpt_callbacks()\n",
    "    \n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train(\n",
    "        callback_list=callback_list\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224, 224]\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory=Path('artifacts/data_ingestion/train')\n",
    "# test_directory=Path('artifacts/data_ingestion/test')\n",
    "# val_directory=Path('artifacts/data_ingestion/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preprocessing layer to the front of VGG\n",
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "# don't train existing weights\n",
    "for layer in vgg.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  # useful for getting number of classes\n",
    "folders = glob('artifacts/data_ingestion/train/*')\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 125445    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14840133 (56.61 MB)\n",
      "Trainable params: 125445 (490.02 KB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(vgg.output)\n",
    "# x = Dense(1000, activation='relu')(x)\n",
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "# create a model object\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "\n",
    "# view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2750 images belonging to 5 classes.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_directory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 15\u001b[0m\n\u001b[0;32m      8\u001b[0m test_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m)\n\u001b[0;32m     10\u001b[0m training_set \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(train_directory,\n\u001b[0;32m     11\u001b[0m                                                  target_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m),\n\u001b[0;32m     12\u001b[0m                                                  batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     13\u001b[0m                                                  class_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m test_set \u001b[38;5;241m=\u001b[39m test_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\u001b[43mtest_directory\u001b[49m,\n\u001b[0;32m     16\u001b[0m                                             target_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m),\n\u001b[0;32m     17\u001b[0m                                             batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     18\u001b[0m                                             class_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_directory' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_directory,\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_directory,\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(training_set))\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mtest_set\u001b[49m))\n\u001b[0;32m      4\u001b[0m r \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit_generator(\n\u001b[0;32m      5\u001b[0m   training_set,\n\u001b[0;32m      6\u001b[0m   validation_data\u001b[38;5;241m=\u001b[39mtest_set,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m   validation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_set)\n\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_set' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(training_set))\n",
    "print(len(test_set))\n",
    "\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=1,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracies\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.7.0.72-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "     ---------------------------------------- 38.2/38.2 MB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\projects\\deep_cnn_classifier1\\env\\lib\\site-packages (from opencv-python) (1.24.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.7.0.72\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('BC.h5')\n",
    "from keras.models import load_model\n",
    "#from keras.preprocessing.image import load_img,img_to_array\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "# from tensorflow.keras.utils import img_to_array\n",
    "# from keras_preprocessing.image import img_to_array\n",
    "import cv2\n",
    "# img = cv2.imread(img_dir)\n",
    "# # from PIL import lo\n",
    "# target_size=(224,224,3)\n",
    "\n",
    "model1 = load_model('C:\\projects\\DEEP_CNN_CLASSIFIER1\\BC.h5',compile=False)  \n",
    "lab = training_set.class_indices\n",
    "lab={k:v for v,k in lab.items()}\n",
    "def output(location):\n",
    "    img=cv2.imread(location)\n",
    "    img=img_to_array(img)\n",
    "    img=img/255\n",
    "    img=np.expand_dims(img,[0])\n",
    "    answer=model1.predict(img)\n",
    "    y_class = answer.argmax(axis=-1)\n",
    "    y = \" \".join(str(x) for x in y_class)\n",
    "    y = int(y)\n",
    "    res = lab[y]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img='artifacts\\data_ingestion\\test\\ABBOTTS BABBLER\\1.jpg'\n",
    "pic=cv2.imread('artifacts\\data_ingestion\\test\\ABBOTTS BABBLER\\1.jpg')\n",
    "#plt.imshow(pic)\n",
    "#output(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype <U49 cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39;49mimshow(\u001b[39m'\u001b[39;49m\u001b[39martifacts\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mdata_ingestion\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39mest\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mABBOTTS BABBLER\u001b[39;49m\u001b[39m\\1\u001b[39;49;00m\u001b[39m.jpg\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\projects\\DEEP_CNN_CLASSIFIER1\\env\\lib\\site-packages\\matplotlib\\pyplot.py:2668\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2662\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mimshow)\n\u001b[0;32m   2663\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimshow\u001b[39m(\n\u001b[0;32m   2664\u001b[0m         X, cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, aspect\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, interpolation\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2665\u001b[0m         alpha\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, origin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, extent\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2666\u001b[0m         interpolation_stage\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, filternorm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, filterrad\u001b[39m=\u001b[39m\u001b[39m4.0\u001b[39m,\n\u001b[0;32m   2667\u001b[0m         resample\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, url\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2668\u001b[0m     __ret \u001b[39m=\u001b[39m gca()\u001b[39m.\u001b[39;49mimshow(\n\u001b[0;32m   2669\u001b[0m         X, cmap\u001b[39m=\u001b[39;49mcmap, norm\u001b[39m=\u001b[39;49mnorm, aspect\u001b[39m=\u001b[39;49maspect,\n\u001b[0;32m   2670\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation, alpha\u001b[39m=\u001b[39;49malpha, vmin\u001b[39m=\u001b[39;49mvmin,\n\u001b[0;32m   2671\u001b[0m         vmax\u001b[39m=\u001b[39;49mvmax, origin\u001b[39m=\u001b[39;49morigin, extent\u001b[39m=\u001b[39;49mextent,\n\u001b[0;32m   2672\u001b[0m         interpolation_stage\u001b[39m=\u001b[39;49minterpolation_stage,\n\u001b[0;32m   2673\u001b[0m         filternorm\u001b[39m=\u001b[39;49mfilternorm, filterrad\u001b[39m=\u001b[39;49mfilterrad, resample\u001b[39m=\u001b[39;49mresample,\n\u001b[0;32m   2674\u001b[0m         url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}),\n\u001b[0;32m   2675\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   2676\u001b[0m     sci(__ret)\n\u001b[0;32m   2677\u001b[0m     \u001b[39mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32mc:\\projects\\DEEP_CNN_CLASSIFIER1\\env\\lib\\site-packages\\matplotlib\\__init__.py:1472\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   1470\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1471\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1472\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1474\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1475\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[0;32m   1476\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\projects\\DEEP_CNN_CLASSIFIER1\\env\\lib\\site-packages\\matplotlib\\axes\\_axes.py:5665\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5657\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m   5658\u001b[0m im \u001b[39m=\u001b[39m mimage\u001b[39m.\u001b[39mAxesImage(\u001b[39mself\u001b[39m, cmap\u001b[39m=\u001b[39mcmap, norm\u001b[39m=\u001b[39mnorm,\n\u001b[0;32m   5659\u001b[0m                       interpolation\u001b[39m=\u001b[39minterpolation, origin\u001b[39m=\u001b[39morigin,\n\u001b[0;32m   5660\u001b[0m                       extent\u001b[39m=\u001b[39mextent, filternorm\u001b[39m=\u001b[39mfilternorm,\n\u001b[0;32m   5661\u001b[0m                       filterrad\u001b[39m=\u001b[39mfilterrad, resample\u001b[39m=\u001b[39mresample,\n\u001b[0;32m   5662\u001b[0m                       interpolation_stage\u001b[39m=\u001b[39minterpolation_stage,\n\u001b[0;32m   5663\u001b[0m                       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 5665\u001b[0m im\u001b[39m.\u001b[39;49mset_data(X)\n\u001b[0;32m   5666\u001b[0m im\u001b[39m.\u001b[39mset_alpha(alpha)\n\u001b[0;32m   5667\u001b[0m \u001b[39mif\u001b[39;00m im\u001b[39m.\u001b[39mget_clip_path() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5668\u001b[0m     \u001b[39m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\projects\\DEEP_CNN_CLASSIFIER1\\env\\lib\\site-packages\\matplotlib\\image.py:701\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39msafe_masked_invalid(A, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    699\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39muint8 \u001b[39mand\u001b[39;00m\n\u001b[0;32m    700\u001b[0m         \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mcan_cast(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mdtype, \u001b[39mfloat\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msame_kind\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[1;32m--> 701\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mImage data of dtype \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m cannot be converted to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    702\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mfloat\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mdtype))\n\u001b[0;32m    704\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    705\u001b[0m     \u001b[39m# If just one dimension assume scalar and apply colormap\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A[:, :, \u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: Image data of dtype <U49 cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbAAAAGiCAYAAACGUJO6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbB0lEQVR4nO3df0zd1f3H8RfQcqmx0DrGhbKrrHX+tqWCZVgb53IniQbXPxaZNYURf0xlRnuz2WJbUKulq7Yjs2hj1ekfOqpGjbEEp0xiVJZGWhKdbU2lFWa8tyWu3I4qtNzz/WPfXocFywf50bc8H8nnD84+537OPWH36b2995LgnHMCAMCYxIleAAAAI0HAAAAmETAAgEkEDABgEgEDAJhEwAAAJhEwAIBJBAwAYBIBAwCYRMAAACZ5Dtjbb7+t4uJizZo1SwkJCXrllVdOOqe5uVmXXHKJfD6fzj77bD399NMjWCoAAF/zHLCenh7NmzdPdXV1wzp/3759uuaaa3TllVeqra1Nd911l2666Sa9/vrrnhcLAMBxCd/ly3wTEhL08ssva/HixUOes3z5cm3btk0ffvhhfOzXv/61Dh06pMbGxpFeGgAwyU0Z6wu0tLQoGAwOGCsqKtJdd9015Jze3l719vbGf47FYvriiy/0gx/8QAkJCWO1VADAGHDO6fDhw5o1a5YSE0fvrRdjHrBwOCy/3z9gzO/3KxqN6ssvv9S0adNOmFNTU6P77rtvrJcGABhHnZ2d+tGPfjRqtzfmARuJyspKhUKh+M/d3d0688wz1dnZqdTU1AlcGQDAq2g0qkAgoOnTp4/q7Y55wDIzMxWJRAaMRSIRpaamDvrsS5J8Pp98Pt8J46mpqQQMAIwa7X8CGvPPgRUWFqqpqWnA2BtvvKHCwsKxvjQA4HvMc8D+85//qK2tTW1tbZL++zb5trY2dXR0SPrvy3+lpaXx82+99Va1t7fr7rvv1u7du/Xoo4/q+eef17Jly0bnHgAAJiXPAXv//fc1f/58zZ8/X5IUCoU0f/58VVVVSZI+//zzeMwk6cc//rG2bdumN954Q/PmzdOGDRv0xBNPqKioaJTuAgBgMvpOnwMbL9FoVGlpaeru7ubfwADAmLF6DOe7EAEAJhEwAIBJBAwAYBIBAwCYRMAAACYRMACASQQMAGASAQMAmETAAAAmETAAgEkEDABgEgEDAJhEwAAAJhEwAIBJBAwAYBIBAwCYRMAAACYRMACASQQMAGASAQMAmETAAAAmETAAgEkEDABgEgEDAJhEwAAAJhEwAIBJBAwAYBIBAwCYRMAAACYRMACASQQMAGASAQMAmETAAAAmETAAgEkEDABgEgEDAJhEwAAAJhEwAIBJBAwAYBIBAwCYRMAAACYRMACASQQMAGASAQMAmETAAAAmETAAgEkEDABgEgEDAJhEwAAAJhEwAIBJBAwAYBIBAwCYRMAAACYRMACASQQMAGASAQMAmETAAAAmETAAgEkEDABgEgEDAJhEwAAAJhEwAIBJBAwAYNKIAlZXV6ecnBylpKSooKBA27dv/9bza2trde6552ratGkKBAJatmyZvvrqqxEtGAAAaQQB27p1q0KhkKqrq7Vjxw7NmzdPRUVFOnDgwKDnP/fcc1qxYoWqq6u1a9cuPfnkk9q6davuueee77x4AMDk5TlgGzdu1M0336zy8nJdcMEF2rx5s0477TQ99dRTg57/3nvvaeHChVqyZIlycnJ01VVX6frrrz/pszYAAL6Np4D19fWptbVVwWDw6xtITFQwGFRLS8ugcy677DK1trbGg9Xe3q6GhgZdffXVQ16nt7dX0Wh0wAEAwP+a4uXkrq4u9ff3y+/3Dxj3+/3avXv3oHOWLFmirq4uXX755XLO6dixY7r11lu/9SXEmpoa3XfffV6WBgCYZMb8XYjNzc1au3atHn30Ue3YsUMvvfSStm3bpjVr1gw5p7KyUt3d3fGjs7NzrJcJADDG0zOw9PR0JSUlKRKJDBiPRCLKzMwcdM7q1au1dOlS3XTTTZKkiy++WD09Pbrlllu0cuVKJSae2FCfzyefz+dlaQCAScbTM7Dk5GTl5eWpqakpPhaLxdTU1KTCwsJB5xw5cuSESCUlJUmSnHNe1wsAgCSPz8AkKRQKqaysTPn5+VqwYIFqa2vV09Oj8vJySVJpaamys7NVU1MjSSouLtbGjRs1f/58FRQUaO/evVq9erWKi4vjIQMAwCvPASspKdHBgwdVVVWlcDis3NxcNTY2xt/Y0dHRMeAZ16pVq5SQkKBVq1bps88+0w9/+EMVFxfrwQcfHL17AQCYdBKcgdfxotGo0tLS1N3drdTU1IleDgDAg7F6DOe7EAEAJhEwAIBJBAwAYBIBAwCYRMAAACYRMACASQQMAGASAQMAmETAAAAmETAAgEkEDABgEgEDAJhEwAAAJhEwAIBJBAwAYBIBAwCYRMAAACYRMACASQQMAGASAQMAmETAAAAmETAAgEkEDABgEgEDAJhEwAAAJhEwAIBJBAwAYBIBAwCYRMAAACYRMACASQQMAGASAQMAmETAAAAmETAAgEkEDABgEgEDAJhEwAAAJhEwAIBJBAwAYBIBAwCYRMAAACYRMACASQQMAGASAQMAmETAAAAmETAAgEkEDABgEgEDAJhEwAAAJhEwAIBJBAwAYBIBAwCYRMAAACYRMACASQQMAGASAQMAmETAAAAmETAAgEkEDABgEgEDAJhEwAAAJhEwAIBJBAwAYNKIAlZXV6ecnBylpKSooKBA27dv/9bzDx06pIqKCmVlZcnn8+mcc85RQ0PDiBYMAIAkTfE6YevWrQqFQtq8ebMKCgpUW1uroqIi7dmzRxkZGSec39fXp1/84hfKyMjQiy++qOzsbH366aeaMWPGaKwfADBJJTjnnJcJBQUFuvTSS7Vp0yZJUiwWUyAQ0B133KEVK1accP7mzZv10EMPaffu3Zo6deqIFhmNRpWWlqbu7m6lpqaO6DYAABNjrB7DPb2E2NfXp9bWVgWDwa9vIDFRwWBQLS0tg8559dVXVVhYqIqKCvn9fl100UVau3at+vv7h7xOb2+votHogAMAgP/lKWBdXV3q7++X3+8fMO73+xUOhwed097erhdffFH9/f1qaGjQ6tWrtWHDBj3wwANDXqempkZpaWnxIxAIeFkmAGASGPN3IcZiMWVkZOjxxx9XXl6eSkpKtHLlSm3evHnIOZWVleru7o4fnZ2dY71MAIAxnt7EkZ6erqSkJEUikQHjkUhEmZmZg87JysrS1KlTlZSUFB87//zzFQ6H1dfXp+Tk5BPm+Hw++Xw+L0sDAEwynp6BJScnKy8vT01NTfGxWCympqYmFRYWDjpn4cKF2rt3r2KxWHzs448/VlZW1qDxAgBgODy/hBgKhbRlyxY988wz2rVrl2677Tb19PSovLxcklRaWqrKysr4+bfddpu++OIL3Xnnnfr444+1bds2rV27VhUVFaN3LwAAk47nz4GVlJTo4MGDqqqqUjgcVm5urhobG+Nv7Ojo6FBi4tddDAQCev3117Vs2TLNnTtX2dnZuvPOO7V8+fLRuxcAgEnH8+fAJgKfAwMAu06Jz4EBAHCqIGAAAJMIGADAJAIGADCJgAEATCJgAACTCBgAwCQCBgAwiYABAEwiYAAAkwgYAMAkAgYAMImAAQBMImAAAJMIGADAJAIGADCJgAEATCJgAACTCBgAwCQCBgAwiYABAEwiYAAAkwgYAMAkAgYAMImAAQBMImAAAJMIGADAJAIGADCJgAEATCJgAACTCBgAwCQCBgAwiYABAEwiYAAAkwgYAMAkAgYAMImAAQBMImAAAJMIGADAJAIGADCJgAEATCJgAACTCBgAwCQCBgAwiYABAEwiYAAAkwgYAMAkAgYAMImAAQBMImAAAJMIGADAJAIGADCJgAEATCJgAACTCBgAwCQCBgAwiYABAEwiYAAAkwgYAMAkAgYAMImAAQBMImAAAJMIGADApBEFrK6uTjk5OUpJSVFBQYG2b98+rHn19fVKSEjQ4sWLR3JZAADiPAds69atCoVCqq6u1o4dOzRv3jwVFRXpwIED3zpv//79+v3vf69FixaNeLEAABznOWAbN27UzTffrPLycl1wwQXavHmzTjvtND311FNDzunv79cNN9yg++67T7Nnzz7pNXp7exWNRgccAAD8L08B6+vrU2trq4LB4Nc3kJioYDColpaWIefdf//9ysjI0I033jis69TU1CgtLS1+BAIBL8sEAEwCngLW1dWl/v5++f3+AeN+v1/hcHjQOe+8846efPJJbdmyZdjXqaysVHd3d/zo7Oz0skwAwCQwZSxv/PDhw1q6dKm2bNmi9PT0Yc/z+Xzy+XxjuDIAgHWeApaenq6kpCRFIpEB45FIRJmZmSec/8knn2j//v0qLi6Oj8Visf9eeMoU7dmzR3PmzBnJugEAk5ynlxCTk5OVl5enpqam+FgsFlNTU5MKCwtPOP+8887TBx98oLa2tvhx7bXX6sorr1RbWxv/tgUAGDHPLyGGQiGVlZUpPz9fCxYsUG1trXp6elReXi5JKi0tVXZ2tmpqapSSkqKLLrpowPwZM2ZI0gnjAAB44TlgJSUlOnjwoKqqqhQOh5Wbm6vGxsb4Gzs6OjqUmMgXfAAAxlaCc85N9CJOJhqNKi0tTd3d3UpNTZ3o5QAAPBirx3CeKgEATCJgAACTCBgAwCQCBgAwiYABAEwiYAAAkwgYAMAkAgYAMImAAQBMImAAAJMIGADAJAIGADCJgAEATCJgAACTCBgAwCQCBgAwiYABAEwiYAAAkwgYAMAkAgYAMImAAQBMImAAAJMIGADAJAIGADCJgAEATCJgAACTCBgAwCQCBgAwiYABAEwiYAAAkwgYAMAkAgYAMImAAQBMImAAAJMIGADAJAIGADCJgAEATCJgAACTCBgAwCQCBgAwiYABAEwiYAAAkwgYAMAkAgYAMImAAQBMImAAAJMIGADAJAIGADCJgAEATCJgAACTCBgAwCQCBgAwiYABAEwiYAAAkwgYAMAkAgYAMImAAQBMImAAAJMIGADAJAIGADCJgAEATCJgAACTCBgAwKQRBayurk45OTlKSUlRQUGBtm/fPuS5W7Zs0aJFizRz5kzNnDlTwWDwW88HAGA4PAds69atCoVCqq6u1o4dOzRv3jwVFRXpwIEDg57f3Nys66+/Xm+99ZZaWloUCAR01VVX6bPPPvvOiwcATF4JzjnnZUJBQYEuvfRSbdq0SZIUi8UUCAR0xx13aMWKFSed39/fr5kzZ2rTpk0qLS0d9Jze3l719vbGf45GowoEAuru7lZqaqqX5QIAJlg0GlVaWtqoP4Z7egbW19en1tZWBYPBr28gMVHBYFAtLS3Duo0jR47o6NGjOuOMM4Y8p6amRmlpafEjEAh4WSYAYBLwFLCuri719/fL7/cPGPf7/QqHw8O6jeXLl2vWrFkDIvhNlZWV6u7ujh+dnZ1elgkAmASmjOfF1q1bp/r6ejU3NyslJWXI83w+n3w+3ziuDABgjaeApaenKykpSZFIZMB4JBJRZmbmt859+OGHtW7dOr355puaO3eu95UCAPA/PL2EmJycrLy8PDU1NcXHYrGYmpqaVFhYOOS89evXa82aNWpsbFR+fv7IVwsAwP/z/BJiKBRSWVmZ8vPztWDBAtXW1qqnp0fl5eWSpNLSUmVnZ6umpkaS9Mc//lFVVVV67rnnlJOTE/+3stNPP12nn376KN4VAMBk4jlgJSUlOnjwoKqqqhQOh5Wbm6vGxsb4Gzs6OjqUmPj1E7vHHntMfX19+tWvfjXgdqqrq3Xvvfd+t9UDACYtz58Dmwhj9RkCAMDYOyU+BwYAwKmCgAEATCJgAACTCBgAwCQCBgAwiYABAEwiYAAAkwgYAMAkAgYAMImAAQBMImAAAJMIGADAJAIGADCJgAEATCJgAACTCBgAwCQCBgAwiYABAEwiYAAAkwgYAMAkAgYAMImAAQBMImAAAJMIGADAJAIGADCJgAEATCJgAACTCBgAwCQCBgAwiYABAEwiYAAAkwgYAMAkAgYAMImAAQBMImAAAJMIGADAJAIGADCJgAEATCJgAACTCBgAwCQCBgAwiYABAEwiYAAAkwgYAMAkAgYAMImAAQBMImAAAJMIGADAJAIGADCJgAEATCJgAACTCBgAwCQCBgAwiYABAEwiYAAAkwgYAMAkAgYAMImAAQBMImAAAJMIGADAJAIGADCJgAEATCJgAACTRhSwuro65eTkKCUlRQUFBdq+ffu3nv/CCy/ovPPOU0pKii6++GI1NDSMaLEAABznOWBbt25VKBRSdXW1duzYoXnz5qmoqEgHDhwY9Pz33ntP119/vW688Ubt3LlTixcv1uLFi/Xhhx9+58UDACavBOec8zKhoKBAl156qTZt2iRJisViCgQCuuOOO7RixYoTzi8pKVFPT49ee+21+NhPf/pT5ebmavPmzYNeo7e3V729vfGfu7u7deaZZ6qzs1OpqalelgsAmGDRaFSBQECHDh1SWlra6N2w86C3t9clJSW5l19+ecB4aWmpu/baawedEwgE3J/+9KcBY1VVVW7u3LlDXqe6utpJ4uDg4OD4Hh2ffPKJl+Sc1BR50NXVpf7+fvn9/gHjfr9fu3fvHnROOBwe9PxwODzkdSorKxUKheI/Hzp0SGeddZY6OjpGt97fM8f/K4dnqt+OfTo59mh42KfhOf4q2hlnnDGqt+spYOPF5/PJ5/OdMJ6WlsYvyTCkpqayT8PAPp0cezQ87NPwJCaO7hvfPd1aenq6kpKSFIlEBoxHIhFlZmYOOiczM9PT+QAADIengCUnJysvL09NTU3xsVgspqamJhUWFg46p7CwcMD5kvTGG28MeT4AAMPh+SXEUCiksrIy5efna8GCBaqtrVVPT4/Ky8slSaWlpcrOzlZNTY0k6c4779QVV1yhDRs26JprrlF9fb3ef/99Pf7448O+ps/nU3V19aAvK+Jr7NPwsE8nxx4ND/s0PGO1T57fRi9JmzZt0kMPPaRwOKzc3Fz9+c9/VkFBgSTpZz/7mXJycvT000/Hz3/hhRe0atUq7d+/Xz/5yU+0fv16XX311aN2JwAAk8+IAgYAwETjuxABACYRMACASQQMAGASAQMAmHTKBIw/0TI8XvZpy5YtWrRokWbOnKmZM2cqGAyedF+/D7z+Lh1XX1+vhIQELV68eGwXeIrwuk+HDh1SRUWFsrKy5PP5dM4550yK/9953afa2lqde+65mjZtmgKBgJYtW6avvvpqnFY7Md5++20VFxdr1qxZSkhI0CuvvHLSOc3Nzbrkkkvk8/l09tlnD3jn+rCN6jcrjlB9fb1LTk52Tz31lPvnP//pbr75ZjdjxgwXiUQGPf/dd991SUlJbv369e6jjz5yq1atclOnTnUffPDBOK98fHndpyVLlri6ujq3c+dOt2vXLveb3/zGpaWluX/961/jvPLx43WPjtu3b5/Lzs52ixYtcr/85S/HZ7ETyOs+9fb2uvz8fHf11Ve7d955x+3bt881Nze7tra2cV75+PK6T88++6zz+Xzu2Wefdfv27XOvv/66y8rKcsuWLRvnlY+vhoYGt3LlSvfSSy85SSd84fs3tbe3u9NOO82FQiH30UcfuUceecQlJSW5xsZGT9c9JQK2YMECV1FREf+5v7/fzZo1y9XU1Ax6/nXXXeeuueaaAWMFBQXut7/97Ziuc6J53advOnbsmJs+fbp75plnxmqJE24ke3Ts2DF32WWXuSeeeMKVlZVNioB53afHHnvMzZ492/X19Y3XEk8JXvepoqLC/fznPx8wFgqF3MKFC8d0naeS4QTs7rvvdhdeeOGAsZKSEldUVOTpWhP+EmJfX59aW1sVDAbjY4mJiQoGg2ppaRl0TktLy4DzJamoqGjI878PRrJP33TkyBEdPXp01L8R+lQx0j26//77lZGRoRtvvHE8ljnhRrJPr776qgoLC1VRUSG/36+LLrpIa9euVX9//3gte9yNZJ8uu+wytba2xl9mbG9vV0NDA1/c8A2j9Rg+4d9GP15/osW6kezTNy1fvlyzZs064Rfn+2Ike/TOO+/oySefVFtb2zis8NQwkn1qb2/X3//+d91www1qaGjQ3r17dfvtt+vo0aOqrq4ej2WPu5Hs05IlS9TV1aXLL79czjkdO3ZMt956q+65557xWLIZQz2GR6NRffnll5o2bdqwbmfCn4FhfKxbt0719fV6+eWXlZKSMtHLOSUcPnxYS5cu1ZYtW5Senj7RyzmlxWIxZWRk6PHHH1deXp5KSkq0cuXKIf+q+mTV3NystWvX6tFHH9WOHTv00ksvadu2bVqzZs1EL+17acKfgfEnWoZnJPt03MMPP6x169bpzTff1Ny5c8dymRPK6x598skn2r9/v4qLi+NjsVhMkjRlyhTt2bNHc+bMGdtFT4CR/C5lZWVp6tSpSkpKio+df/75CofD6uvrU3Jy8piueSKMZJ9Wr16tpUuX6qabbpIkXXzxxerp6dEtt9yilStXjvrfw7JqqMfw1NTUYT/7kk6BZ2D8iZbhGck+SdL69eu1Zs0aNTY2Kj8/fzyWOmG87tF5552nDz74QG1tbfHj2muv1ZVXXqm2tjYFAoHxXP64Gcnv0sKFC7V379544CXp448/VlZW1vcyXtLI9unIkSMnROp49B1fOxs3ao/h3t5fMjbq6+udz+dzTz/9tPvoo4/cLbfc4mbMmOHC4bBzzrmlS5e6FStWxM9/99133ZQpU9zDDz/sdu3a5aqrqyfN2+i97NO6detccnKye/HFF93nn38ePw4fPjxRd2HMed2jb5os70L0uk8dHR1u+vTp7ne/+53bs2ePe+2111xGRoZ74IEHJuoujAuv+1RdXe2mT5/u/vrXv7r29nb3t7/9zc2ZM8ddd911E3UXxsXhw4fdzp073c6dO50kt3HjRrdz50736aefOuecW7FihVu6dGn8/ONvo//DH/7gdu3a5erq6uy+jd455x555BF35plnuuTkZLdgwQL3j3/8I/6/XXHFFa6srGzA+c8//7w755xzXHJysrvwwgvdtm3bxnnFE8PLPp111llO0glHdXX1+C98HHn9XfpfkyVgznnfp/fee88VFBQ4n8/nZs+e7R588EF37NixcV71+POyT0ePHnX33nuvmzNnjktJSXGBQMDdfvvt7t///vf4L3wcvfXWW4M+1hzfm7KyMnfFFVecMCc3N9clJye72bNnu7/85S+er8ufUwEAmDTh/wYGAMBIEDAAgEkEDABgEgEDAJhEwAAAJhEwAIBJBAwAYBIBAwCYRMAAACYRMACASQQMAGDS/wFzTP77mPX4nAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow('artifacts\\data_ingestion\\test\\ABBOTTS BABBLER\\1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'artifacts\\\\data_ingestion\\test\\\\ABBOTTS BABBLER\\x01.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mprojects\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDEEP_CNN_CLASSIFIER1\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mBC.h5\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m# loading the already saved model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m#uploaded_file = st.file_uploader(\"Choose a file\") # uploading the file to the streamlit server\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# if uploaded_file is not None:\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m#     # To read file as bytes:\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(img) \u001b[39m# This will contain file in some unreadable format basically in bytes format\u001b[39;00m\n\u001b[0;32m      9\u001b[0m img1 \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mresize((\u001b[39m224\u001b[39m,\u001b[39m224\u001b[39m)) \n\u001b[0;32m     10\u001b[0m img_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(img1)\n",
      "File \u001b[1;32mc:\\projects\\DEEP_CNN_CLASSIFIER1\\env\\lib\\site-packages\\PIL\\Image.py:3227\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3224\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[0;32m   3226\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> 3227\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   3228\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   3230\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'artifacts\\\\data_ingestion\\test\\\\ABBOTTS BABBLER\\x01.jpg'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "model = tf.keras.models.load_model(\"C:\\projects\\DEEP_CNN_CLASSIFIER1\\BC.h5\") # loading the already saved model\n",
    "#uploaded_file = st.file_uploader(\"Choose a file\") # uploading the file to the streamlit server\n",
    "# if uploaded_file is not None:\n",
    "#     # To read file as bytes:\n",
    "\n",
    "image = Image.open() # This will contain file in some unreadable format basically in bytes format\n",
    "img1 = image.resize((224,224)) \n",
    "img_array = np.array(img1)\n",
    "img_array = np.expand_dims(img_array, axis=0) # [batch_size, row, col, channel]\n",
    "result = model.predict(img_array) # [[0.99, 0.01], [0.99, 0.01]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 13:53:31.505 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\projects\\DEEP_CNN_CLASSIFIER1\\env\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('C:\\projects\\DEEP_CNN_CLASSIFIER1\\BC.h5',compile=False)\n",
    "lab = {0: 'AFRICAN CROWNED CRANE', 1: 'AFRICAN FIREFINCH', 2: 'ALBATROSS', 3: 'ALEXANDRINE PARAKEET', 4: 'AMERICAN AVOCET', 5: 'AMERICAN BITTERN', 6: 'AMERICAN COOT', 7: 'AMERICAN GOLDFINCH', 8: 'AMERICAN KESTREL', 9: 'AMERICAN PIPIT', 10: 'AMERICAN REDSTART', 11: 'ANHINGA', 12: 'ANNAS HUMMINGBIRD', 13: 'ANTBIRD', 14: 'ARARIPE MANAKIN', 15: 'ASIAN CRESTED IBIS', 16: 'BALD EAGLE', 17: 'BALI STARLING', 18: 'BALTIMORE ORIOLE', 19: 'BANANAQUIT', 20: 'BANDED BROADBILL', 21: 'BAR-TAILED GODWIT', 22: 'BARN OWL', 23: 'BARN SWALLOW', 24: 'BARRED PUFFBIRD', 25: 'BAY-BREASTED WARBLER', 26: 'BEARDED BARBET', 27: 'BEARDED REEDLING', 28: 'BELTED KINGFISHER', 29: 'BIRD OF PARADISE', 30: 'BLACK & YELLOW bROADBILL', 31: 'BLACK FRANCOLIN', 32: 'BLACK SKIMMER', 33: 'BLACK SWAN', 34: 'BLACK TAIL CRAKE', 35: 'BLACK THROATED BUSHTIT', 36: 'BLACK THROATED WARBLER', 37: 'BLACK VULTURE', 38: 'BLACK-CAPPED CHICKADEE', 39: 'BLACK-NECKED GREBE', 40: 'BLACK-THROATED SPARROW', 41: 'BLACKBURNIAM WARBLER', 42: 'BLUE GROUSE', 43: 'BLUE HERON', 44: 'BOBOLINK', 45: 'BORNEAN BRISTLEHEAD', 46: 'BORNEAN LEAFBIRD', 47: 'BROWN NOODY', 48: 'BROWN THRASHER', 49: 'BULWERS PHEASANT', 50: 'CACTUS WREN', 51: 'CALIFORNIA CONDOR', 52: 'CALIFORNIA GULL', 53: 'CALIFORNIA QUAIL', 54: 'CANARY', 55: 'CAPE MAY WARBLER', 56: 'CAPUCHINBIRD', 57: 'CARMINE BEE-EATER', 58: 'CASPIAN TERN', 59: 'CASSOWARY', 60: 'CEDAR WAXWING', 61: 'CHARA DE COLLAR', 62: 'CHIPPING SPARROW', 63: 'CHUKAR PARTRIDGE', 64: 'CINNAMON TEAL', 65: 'COCK OF THE  ROCK', 66: 'COCKATOO', 67: 'COMMON FIRECREST', 68: 'COMMON GRACKLE', 69: 'COMMON HOUSE MARTIN', 70: 'COMMON LOON', 71: 'COMMON POORWILL', 72: 'COMMON STARLING', 73: 'COUCHS KINGBIRD', 74: 'CRESTED AUKLET', 75: 'CRESTED CARACARA', 76: 'CRESTED NUTHATCH', 77: 'CROW', 78: 'CROWNED PIGEON', 79: 'CUBAN TODY', 80: 'CURL CRESTED ARACURI', 81: 'D-ARNAUDS BARBET', 82: 'DARK EYED JUNCO', 83: 'DOUBLE BARRED FINCH', 84: 'DOWNY WOODPECKER', 85: 'EASTERN BLUEBIRD', 86: 'EASTERN MEADOWLARK', 87: 'EASTERN ROSELLA', 88: 'EASTERN TOWEE', 89: 'ELEGANT TROGON', 90: 'ELLIOTS  PHEASANT', 91: 'EMPEROR PENGUIN', 92: 'EMU', 93: 'ENGGANO MYNA', 94: 'EURASIAN GOLDEN ORIOLE', 95: 'EURASIAN MAGPIE', 96: 'EVENING GROSBEAK', 97: 'FIRE TAILLED MYZORNIS', 98: 'FLAME TANAGER', 99: 'FLAMINGO', 100: 'FRIGATE', 101: 'GAMBELS QUAIL', 102: 'GANG GANG COCKATOO', 103: 'GILA WOODPECKER', 104: 'GILDED FLICKER', 105: 'GLOSSY IBIS', 106: 'GO AWAY BIRD', 107: 'GOLD WING WARBLER', 108: 'GOLDEN CHEEKED WARBLER', 109: 'GOLDEN CHLOROPHONIA', 110: 'GOLDEN EAGLE', 111: 'GOLDEN PHEASANT', 112: 'GOLDEN PIPIT', 113: 'GOULDIAN FINCH', 114: 'GRAY CATBIRD', 115: 'GRAY PARTRIDGE', 116: 'GREAT POTOO', 117: 'GREATOR SAGE GROUSE', 118: 'GREEN JAY', 119: 'GREEN MAGPIE', 120: 'GREY PLOVER', 121: 'GUINEA TURACO', 122: 'GUINEAFOWL', 123: 'GYRFALCON', 124: 'HARPY EAGLE', 125: 'HAWAIIAN GOOSE', 126: 'HELMET VANGA', 127: 'HIMALAYAN MONAL', 128: 'HOATZIN', 129: 'HOODED MERGANSER', 130: 'HOOPOES', 131: 'HORNBILL', 132: 'HORNED GUAN', 133: 'HORNED SUNGEM', 134: 'HOUSE FINCH', 135: 'HOUSE SPARROW', 136: 'IMPERIAL SHAQ', 137: 'INCA TERN', 138: 'INDIAN BUSTARD', 139: 'INDIAN PITTA', 140: 'INDIGO BUNTING', 141: 'JABIRU', 142: 'JAVA SPARROW', 143: 'KAKAPO', 144: 'KILLDEAR', 145: 'KING VULTURE', 146: 'KIWI', 147: 'KOOKABURRA', 148: 'LARK BUNTING', 149: 'LEARS MACAW', 150: 'LILAC ROLLER', 151: 'LONG-EARED OWL', 152: 'MAGPIE GOOSE', 153: 'MALABAR HORNBILL', 154: 'MALACHITE KINGFISHER', 155: 'MALEO', 156: 'MALLARD DUCK', 157: 'MANDRIN DUCK', 158: 'MARABOU STORK', 159: 'MASKED BOOBY', 160: 'MASKED LAPWING', 161: 'MIKADO  PHEASANT', 162: 'MOURNING DOVE', 163: 'MYNA', 164: 'NICOBAR PIGEON', 165: 'NOISY FRIARBIRD', 166: 'NORTHERN BALD IBIS', 167: 'NORTHERN CARDINAL', 168: 'NORTHERN FLICKER', 169: 'NORTHERN GANNET', 170: 'NORTHERN GOSHAWK', 171: 'NORTHERN JACANA', 172: 'NORTHERN MOCKINGBIRD', 173: 'NORTHERN PARULA', 174: 'NORTHERN RED BISHOP', 175: 'NORTHERN SHOVELER', 176: 'OCELLATED TURKEY', 177: 'OKINAWA RAIL', 178: 'OSPREY', 179: 'OSTRICH', 180: 'OYSTER CATCHER', 181: 'PAINTED BUNTIG', 182: 'PALILA', 183: 'PARADISE TANAGER', 184: 'PARUS MAJOR', 185: 'PEACOCK', 186: 'PELICAN', 187: 'PEREGRINE FALCON', 188: 'PHILIPPINE EAGLE', 189: 'PINK ROBIN', 190: 'PUFFIN', 191: 'PURPLE FINCH', 192: 'PURPLE GALLINULE', 193: 'PURPLE MARTIN', 194: 'PURPLE SWAMPHEN', 195: 'QUETZAL', 196: 'RAINBOW LORIKEET', 197: 'RAZORBILL', 198: 'RED BEARDED BEE EATER', 199: 'RED BELLIED PITTA', 200: 'RED BROWED FINCH', 201: 'RED FACED CORMORANT', 202: 'RED FACED WARBLER', 203: 'RED HEADED DUCK', 204: 'RED HEADED WOODPECKER', 205: 'RED HONEY CREEPER', 206: 'RED TAILED THRUSH', 207: 'RED WINGED BLACKBIRD', 208: 'RED WISKERED BULBUL', 209: 'REGENT BOWERBIRD', 210: 'RING-NECKED PHEASANT', 211: 'ROADRUNNER', 212: 'ROBIN', 213: 'ROCK DOVE', 214: 'ROSY FACED LOVEBIRD', 215: 'ROUGH LEG BUZZARD', 216: 'ROYAL FLYCATCHER', 217: 'RUBY THROATED HUMMINGBIRD', 218: 'RUFOUS KINGFISHER', 219: 'RUFUOS MOTMOT', 220: 'SAMATRAN THRUSH', 221: 'SAND MARTIN', 222: 'SCARLET IBIS', 223: 'SCARLET MACAW', 224: 'SHOEBILL', 225: 'SHORT BILLED DOWITCHER', 226: 'SMITHS LONGSPUR', 227: 'SNOWY EGRET', 228: 'SNOWY OWL', 229: 'SORA', 230: 'SPANGLED COTINGA', 231: 'SPLENDID WREN', 232: 'SPOON BILED SANDPIPER', 233: 'SPOONBILL', 234: 'SRI LANKA BLUE MAGPIE', 235: 'STEAMER DUCK', 236: 'STORK BILLED KINGFISHER', 237: 'STRAWBERRY FINCH', 238: 'STRIPPED SWALLOW', 239: 'SUPERB STARLING', 240: 'SWINHOES PHEASANT', 241: 'TAIWAN MAGPIE', 242: 'TAKAHE', 243: 'TASMANIAN HEN', 244: 'TEAL DUCK', 245: 'TIT MOUSE', 246: 'TOUCHAN', 247: 'TOWNSENDS WARBLER', 248: 'TREE SWALLOW', 249: 'TRUMPTER SWAN', 250: 'TURKEY VULTURE', 251: 'TURQUOISE MOTMOT', 252: 'UMBRELLA BIRD', 253: 'VARIED THRUSH', 254: 'VENEZUELIAN TROUPIAL', 255: 'VERMILION FLYCATHER', 256: 'VICTORIA CROWNED PIGEON', 257: 'VIOLET GREEN SWALLOW', 258: 'VULTURINE GUINEAFOWL', 259: 'WATTLED CURASSOW', 260: 'WHIMBREL', 261: 'WHITE CHEEKED TURACO', 262: 'WHITE NECKED RAVEN', 263: 'WHITE TAILED TROPIC', 264: 'WILD TURKEY', 265: 'WILSONS BIRD OF PARADISE', 266: 'WOOD DUCK', 267: 'YELLOW BELLIED FLOWERPECKER', 268: 'YELLOW CACIQUE', 269: 'YELLOW HEADED BLACKBIRD'}\n",
    "\n",
    "def processed_img(img_path):\n",
    "    img=tf.keras.preprocessing.image.load_img(img_path,target_size=(224,224,3))\n",
    "    img=img_to_array(img)\n",
    "    img=img/255\n",
    "    img=np.expand_dims(img,[0])\n",
    "    answer=model.predict(img)\n",
    "    y_class = answer.argmax(axis=-1)\n",
    "    print(y_class)\n",
    "    y = \" \".join(str(x) for x in y_class)\n",
    "    y = int(y)\n",
    "    res = lab[y]\n",
    "    print(res)\n",
    "    return res\n",
    "\n",
    "def run():\n",
    "    img1 = Image.open('C:\\projects\\DEEP_CNN_CLASSIFIER1\\download.jpeg')\n",
    "    img1 = img1.resize((350,350))\n",
    "    st.image(img1,use_column_width=False)\n",
    "    st.title(\"Birds Species Classification\")\n",
    "    st.markdown('''<h4 style='text-align: left; color: #d73b5c;'>* Data is based \"270 Bird Species also see 70 Sports Dataset\"</h4>''',\n",
    "                unsafe_allow_html=True)\n",
    "\n",
    "    img_file = st.file_uploader(\"Choose an Image of Bird\", type=[\"jpg\", \"png\"])\n",
    "    if img_file is not None:\n",
    "        st.image(img_file,use_column_width=False)\n",
    "        save_image_path = './upload_images/'+img_file.name\n",
    "        with open(save_image_path, \"wb\") as f:\n",
    "            f.write(img_file.getbuffer())\n",
    "\n",
    "        if st.button(\"Predict\"):\n",
    "            result = processed_img(save_image_path)\n",
    "            st.success(\"Predicted Bird is: \"+result)\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "def run():\n",
    "    \"\"\"\n",
    "\n",
    "    #  IMAGE CLASSIFICATION PROJECT \n",
    "\n",
    "    \"\"\"\n",
    "    model = tf.keras.models.load_model(\"C:\\projects\\DEEP_CNN_CLASSIFIER1\\BC.h5\") # loading the already saved model\n",
    "    uploaded_file = st.file_uploader(\"Choose a file\") # uploading the file to the streamlit server\n",
    "    if uploaded_file is not None:\n",
    "        # To read file as bytes:\n",
    "\n",
    "        image = Image.open(uploaded_file) # This will contain file in some unreadable format basically in bytes format\n",
    "        img = image.resize((224,224)) \n",
    "        img_array = np.array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0) # [batch_size, row, col, channel]\n",
    "        result = model.predict(img_array) # [[0.99, 0.01], [0.99, 0.01]]\n",
    "\n",
    "        argmax_index = np.argmax(result, axis=1) # [0, 0]\n",
    "        if argmax_index[0] == 0:\n",
    "            st.image(image, caption=\"predicted: cat\")\n",
    "        else:\n",
    "            st.image(image, caption='predicted: dog')\n",
    "\n",
    "run()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "import cv2\n",
    "def is_bird(image_path):\n",
    "    # Load the object detection model\n",
    "    model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    model.eval()\n",
    "    \n",
    "    # Load the image and convert it to a tensor\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    tensor = torch.from_numpy(image).permute(2,0,1).unsqueeze(0).float()\n",
    "    \n",
    "    # Run the image through the object detection model\n",
    "    with torch.no_grad():\n",
    "        output = model(tensor)\n",
    "    \n",
    "    # Check if any detected object is not a bird\n",
    "    for i in range(output[0]['labels'].shape[0]):\n",
    "        label = output[0]['labels'][i].item()\n",
    "        if label != 16: # 16 is the label index for birds in the COCO dataset\n",
    "            return False\n",
    "    \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\projects\\DEEP_CNN_CLASSIFIER1\\env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\projects\\DEEP_CNN_CLASSIFIER1\\env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m is_bird(\u001b[39m\"\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mprojects\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mDEEP_CNN_CLASSIFIER1\u001b[39;49m\u001b[39m\\a\u001b[39;49;00m\u001b[39mrtifacts\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mdata_ingestion\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39mrain\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mABBOTTS BABBLER\u001b[39;49m\u001b[39m\\001\u001b[39;49;00m\u001b[39m.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m, in \u001b[0;36mis_bird\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39m# Load the image and convert it to a tensor\u001b[39;00m\n\u001b[0;32m     10\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(image_path)\n\u001b[1;32m---> 11\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(image, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2RGB)\n\u001b[0;32m     12\u001b[0m tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(image)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m     14\u001b[0m \u001b[39m# Run the image through the object detection model\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "is_bird(\"C:\\projects\\DEEP_CNN_CLASSIFIER1\\artifacts\\data_ingestion\\train\\ABBOTTS BABBLER\\001.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_bird(\"C:\\projects\\DEEP_CNN_CLASSIFIER1\\photo-1606567595334-d39972c85dbe.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar cascade classifier for bird detection\n",
    "bird_cascade = cv2.CascadeClassifier('bird_cascade.xml')\n",
    "\n",
    "# Define a function to check if an image is a bird image or not\n",
    "def is_bird_image(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect bird objects in the image using the bird cascade classifier\n",
    "    birds = bird_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    # If there are no bird objects detected, return False\n",
    "    if len(birds) == 0:\n",
    "        return False\n",
    "\n",
    "    # Otherwise, return True\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m image_path\u001b[39m=\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mprojects\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDEEP_CNN_CLASSIFIER1\u001b[39m\u001b[39m\\\u001b[39m\u001b[39martifacts\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdata_ingestion\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mYELLOW BELLIED FLOWERPECKER\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m154.jpg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m is_bird_image(image_path\u001b[39m=\u001b[39;49mimage_path)\n",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m, in \u001b[0;36mis_bird_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     12\u001b[0m gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     14\u001b[0m \u001b[39m# Detect bird objects in the image using the bird cascade classifier\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m birds \u001b[39m=\u001b[39m bird_cascade\u001b[39m.\u001b[39;49mdetectMultiScale(gray, scaleFactor\u001b[39m=\u001b[39;49m\u001b[39m1.1\u001b[39;49m, minNeighbors\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[0;32m     17\u001b[0m \u001b[39m# If there are no bird objects detected, return False\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(birds) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "image_path=r\"C:\\projects\\DEEP_CNN_CLASSIFIER1\\artifacts\\data_ingestion\\train\\YELLOW BELLIED FLOWERPECKER\\154.jpg\"\n",
    "is_bird_image(image_path=image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ee389b6fd5680d01c44917c1212b4c09ead7d0a63469ff6d06dd80212d603e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
